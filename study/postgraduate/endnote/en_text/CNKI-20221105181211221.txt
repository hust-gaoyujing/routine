%0 Thesis
%A 冯佳玮
%T 基于FPGA的二值卷积神经网络加速研究与实现
%Y 李述
%I 哈尔滨理工大学
%9 硕士
%D 2022
%K 卷积神经网络;FPGA;硬件加速
%X 近年来,随着人工智能在生活生产中的大规模应用,深度学习算法也被越来越多的研究者关注。卷积神经网络作为深度学习中应用较为广泛的算法,在诸多领域都取得了较好的效果。但是随着网络规模逐渐增大,对应的计算量也随之快速增大,限制了网络模型的应用场景。目前主流的神经网络部署平台以CPU,GPU为主,但是这两种平台功耗较高,设备尺寸也较大,无法部署在一些有功耗限制的移动端应用场景。二值化卷积神经网络将权重量化为+1或-1,使得计算时避免了乘法运算,同时二值化权重保存只需要1个bit,有效降低了对存储空间的要求。FPGA现场可编程门阵列是一种有着丰富逻辑和运算资源,具备高度并行,灵活可配置等特性的计算设备。十分适合作为二值化卷积神经网络的部署平台。本文基于FPGA平台,针对二值化卷积神经网络的前向计算过程进行加速研究。首先研究了卷积神经网络的原理和模型结构特点,分析了网络模型二值化后在硬件上的表达方式,通过将卷积中乘法替换为同或(XNOR)和popcount的方式提高了运算效率,有效减少了硬件实现时乘法器的使用。根据网络模型中各层的计算的特点以及网络前向计算过程中的并行性,采用流水线方式设计了网络模型的并行加速计算模块,包括卷积层模块,池化层模块,激活函数和全连接层模块。其中,在数据的缓冲方式上,本文改进了传统卷积层和池化层使用的行缓冲方式,降低了数据缓冲需要的寄存器资源使用量。在实现方式上,主要采用RTL方式实现,在Quartus Ⅱ软件中进行编译,最终完成算法整体的硬件电路设计。最后在Altera公司的DE2-115 FPGA开发板上对设计进行了实验,证明了设计的加速系统的有效性。实验结果显示,将本文的方法用来执行对CIFAR-10数据集的分类任务时,识别的速度相比CPU平台提高了1.47倍的同时,最大误差控制在0.051。
%R 10.27063/d.cnki.ghlgu.2022.000436
%W CNKI



